# File generated by CompCert 2.4
# Command line: -stdlib /home/michael/.opam/4.02.1/lib/compcert/ -fstruct-return -dasm -lcompcert -I /home/michael/.opam/4.02.1/share/compcert-bench/raytracer /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/memory.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/gmllexer.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/gmlparser.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/eval.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/arrays.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/vector.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/matrix.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/object.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/intersect.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/surface.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/light.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/simplify.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/render.c /home/michael/.opam/4.02.1/share/compcert-bench/raytracer/main.c -lm
	.section	.rodata
	.align	1
__stringlit_1:
	.ascii	"/home/michael/.opam/4.02.1/share/compcert-bench/raytracer/object.c\000"
	.type	__stringlit_1, @object
	.size	__stringlit_1, . - __stringlit_1
	.section	.rodata
	.align	1
__stringlit_2:
	.ascii	"0\000"
	.type	__stringlit_2, @object
	.size	__stringlit_2, . - __stringlit_2
	.text
	.align	16
new_object:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %edx
	movl	%edx, 4(%esp)
	movl	%ebx, 8(%esp)
	movl	%esi, 12(%esp)
	movl	0(%edx), %esi
	movl	4(%edx), %ecx
	leal	16(%esp), %eax
	movl	%ecx, %edx
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	$68, %edx
	movl	%edx, 0(%esp)
	call	arena_alloc
	movl	%eax, %ebx
	movl	%esi, 0(%ebx)
	leal	4(%ebx), %eax
	leal	16(%esp), %edx
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	mid, %ecx
	movl	%ecx, 16(%ebx)
	movl	%ecx, 12(%ebx)
	movsd	.L297, %xmm2 # 1
	movsd	%xmm2, 20(%ebx)
	movsd	.L298, %xmm0 # -1
	movsd	%xmm0, 60(%ebx)
	movl	%ebx, %eax
	movl	8(%esp), %ebx
	movl	12(%esp), %esi
	addl	$28, %esp
	ret
	.cfi_endproc
	.type	new_object, @function
	.size	new_object, . - new_object
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L298:	.quad	0xbff0000000000000
.L297:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl cone
cone:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %edx
	movl	%edx, 8(%esp)
	movl	0(%edx), %edx
	leal	16(%esp), %eax
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	xorl	%ecx, %ecx
	leal	16(%esp), %edx
	movl	%ecx, 0(%esp)
	movl	%edx, 4(%esp)
	call	new_object
	addl	$28, %esp
	ret
	.cfi_endproc
	.type	cone, @function
	.size	cone, . - cone
	.text
	.align	16
	.globl cube
cube:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %edx
	movl	%edx, 8(%esp)
	movl	0(%edx), %edx
	leal	16(%esp), %eax
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	$1, %ecx
	leal	16(%esp), %edx
	movl	%ecx, 0(%esp)
	movl	%edx, 4(%esp)
	call	new_object
	addl	$28, %esp
	ret
	.cfi_endproc
	.type	cube, @function
	.size	cube, . - cube
	.text
	.align	16
	.globl cylinder
cylinder:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %edx
	movl	%edx, 8(%esp)
	movl	0(%edx), %edx
	leal	16(%esp), %eax
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	$2, %ecx
	leal	16(%esp), %edx
	movl	%ecx, 0(%esp)
	movl	%edx, 4(%esp)
	call	new_object
	addl	$28, %esp
	ret
	.cfi_endproc
	.type	cylinder, @function
	.size	cylinder, . - cylinder
	.text
	.align	16
	.globl plane
plane:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %edx
	movl	%edx, 8(%esp)
	movl	0(%edx), %edx
	leal	16(%esp), %eax
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	$3, %ecx
	leal	16(%esp), %edx
	movl	%ecx, 0(%esp)
	movl	%edx, 4(%esp)
	call	new_object
	addl	$28, %esp
	ret
	.cfi_endproc
	.type	plane, @function
	.size	plane, . - plane
	.text
	.align	16
	.globl sphere
sphere:
	.cfi_startproc
	subl	$28, %esp
	.cfi_adjust_cfa_offset	28
	leal	32(%esp), %edx
	movl	%edx, 8(%esp)
	movl	0(%edx), %edx
	leal	16(%esp), %eax
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	$4, %ecx
	leal	16(%esp), %edx
	movl	%ecx, 0(%esp)
	movl	%edx, 4(%esp)
	call	new_object
	addl	$28, %esp
	ret
	.cfi_endproc
	.type	sphere, @function
	.size	sphere, . - sphere
	.text
	.align	16
transform:
	.cfi_startproc
	subl	$52, %esp
	.cfi_adjust_cfa_offset	52
	leal	56(%esp), %edx
	movl	%edx, 20(%esp)
	movl	%ebx, 24(%esp)
	movl	%esi, 28(%esp)
	movl	%edi, 32(%esp)
	movl	%ebp, 36(%esp)
	movl	0(%edx), %edi
	movl	4(%edx), %esi
	movl	8(%edx), %ebp
	movsd	12(%edx), %xmm6
	movsd	%xmm6, 40(%esp)
	movl	$68, %edx
	movl	%edx, 0(%esp)
	call	arena_alloc
	movl	%eax, %ebx
	movl	0(%edi), %edx
	movl	%edx, 0(%ebx)
	movl	0(%edi), %ecx
	cmpl	$5, %ecx
	je	.L299
	cmpl	$6, %ecx
	je	.L299
	cmpl	$7, %ecx
	je	.L299
	leal	4(%ebx), %eax
	leal	4(%edi), %edx
# begin builtin __builtin_memcpy_aligned, size = 8, alignment = 4
	movq	0(%edx), %xmm7
	movq	%xmm7, 0(%eax)
# end builtin __builtin_memcpy_aligned
	movl	12(%edi), %eax
	movl	%eax, 0(%esp)
	movl	%ebp, 4(%esp)
	call	mcompose
	movl	%eax, 12(%ebx)
	movl	16(%edi), %edx
	movl	%esi, 0(%esp)
	movl	%edx, 4(%esp)
	call	mcompose
	movl	%eax, 16(%ebx)
	movsd	20(%edi), %xmm1
	movsd	40(%esp), %xmm0
	mulsd	%xmm0, %xmm1
	movsd	%xmm1, 20(%ebx)
	jmp	.L300
.L299:
	movl	28(%edi), %eax
	movl	%eax, 0(%esp)
	movl	%esi, 4(%esp)
	movl	%ebp, 8(%esp)
	movsd	40(%esp), %xmm2
	movsd	%xmm2, 12(%esp)
	call	transform
	movl	%eax, 28(%ebx)
	movl	32(%edi), %edx
	movl	%edx, 0(%esp)
	movl	%esi, 4(%esp)
	movl	%ebp, 8(%esp)
	movsd	40(%esp), %xmm3
	movsd	%xmm3, 12(%esp)
	call	transform
	movl	%eax, 32(%ebx)
.L300:
	movsd	.L301, %xmm7 # -1
	movsd	%xmm7, 60(%ebx)
	movl	%ebx, %eax
	movl	24(%esp), %ebx
	movl	28(%esp), %esi
	movl	32(%esp), %edi
	movl	36(%esp), %ebp
	addl	$52, %esp
	ret
	.cfi_endproc
	.type	transform, @function
	.size	transform, . - transform
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L301:	.quad	0xbff0000000000000
	.text
	.align	16
	.globl orotatex
orotatex:
	.cfi_startproc
	subl	$44, %esp
	.cfi_adjust_cfa_offset	44
	leal	48(%esp), %edx
	movl	%edx, 20(%esp)
	movl	%ebx, 24(%esp)
	movl	%esi, 28(%esp)
	movl	0(%edx), %esi
	movsd	4(%edx), %xmm4
	movsd	%xmm4, 32(%esp)
	movsd	32(%esp), %xmm1
	movsd	%xmm1, 0(%esp)
	call	mrotatex
	movl	%eax, %ebx
	movsd	32(%esp), %xmm0
	xorpd	__negd_mask, %xmm0
	movsd	%xmm0, 0(%esp)
	call	mrotatex
	movsd	.L302, %xmm3 # 1
	movl	%esi, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%eax, 8(%esp)
	movsd	%xmm3, 12(%esp)
	call	transform
	movl	24(%esp), %ebx
	movl	28(%esp), %esi
	addl	$44, %esp
	ret
	.cfi_endproc
	.type	orotatex, @function
	.size	orotatex, . - orotatex
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L302:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl orotatey
orotatey:
	.cfi_startproc
	subl	$44, %esp
	.cfi_adjust_cfa_offset	44
	leal	48(%esp), %edx
	movl	%edx, 20(%esp)
	movl	%ebx, 24(%esp)
	movl	%esi, 28(%esp)
	movl	0(%edx), %esi
	movsd	4(%edx), %xmm4
	movsd	%xmm4, 32(%esp)
	movsd	32(%esp), %xmm1
	movsd	%xmm1, 0(%esp)
	call	mrotatey
	movl	%eax, %ebx
	movsd	32(%esp), %xmm0
	xorpd	__negd_mask, %xmm0
	movsd	%xmm0, 0(%esp)
	call	mrotatey
	movsd	.L303, %xmm3 # 1
	movl	%esi, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%eax, 8(%esp)
	movsd	%xmm3, 12(%esp)
	call	transform
	movl	24(%esp), %ebx
	movl	28(%esp), %esi
	addl	$44, %esp
	ret
	.cfi_endproc
	.type	orotatey, @function
	.size	orotatey, . - orotatey
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L303:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl orotatez
orotatez:
	.cfi_startproc
	subl	$44, %esp
	.cfi_adjust_cfa_offset	44
	leal	48(%esp), %edx
	movl	%edx, 20(%esp)
	movl	%ebx, 24(%esp)
	movl	%esi, 28(%esp)
	movl	0(%edx), %esi
	movsd	4(%edx), %xmm4
	movsd	%xmm4, 32(%esp)
	movsd	32(%esp), %xmm1
	movsd	%xmm1, 0(%esp)
	call	mrotatez
	movl	%eax, %ebx
	movsd	32(%esp), %xmm0
	xorpd	__negd_mask, %xmm0
	movsd	%xmm0, 0(%esp)
	call	mrotatez
	movsd	.L304, %xmm3 # 1
	movl	%esi, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%eax, 8(%esp)
	movsd	%xmm3, 12(%esp)
	call	transform
	movl	24(%esp), %ebx
	movl	28(%esp), %esi
	addl	$44, %esp
	ret
	.cfi_endproc
	.type	orotatez, @function
	.size	orotatez, . - orotatez
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L304:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl oscale
oscale:
	.cfi_startproc
	subl	$76, %esp
	.cfi_adjust_cfa_offset	76
	leal	80(%esp), %edx
	movl	%edx, 24(%esp)
	movl	%ebx, 28(%esp)
	movl	%esi, 32(%esp)
	movl	0(%edx), %esi
	movsd	4(%edx), %xmm3
	movsd	%xmm3, 48(%esp)
	movsd	12(%edx), %xmm3
	movsd	%xmm3, 64(%esp)
	movsd	20(%edx), %xmm3
	movsd	%xmm3, 56(%esp)
	movsd	48(%esp), %xmm4
	movsd	%xmm4, 40(%esp)
	movsd	64(%esp), %xmm5
	comisd	%xmm4, %xmm5
	jbe	.L305
	movsd	%xmm5, 40(%esp)
.L305:
	movsd	56(%esp), %xmm0
	movsd	40(%esp), %xmm6
	comisd	%xmm6, %xmm0
	jbe	.L306
	movsd	%xmm0, 40(%esp)
.L306:
	movsd	48(%esp), %xmm5
	movsd	%xmm5, 0(%esp)
	movsd	64(%esp), %xmm5
	movsd	%xmm5, 8(%esp)
	movsd	56(%esp), %xmm5
	movsd	%xmm5, 16(%esp)
	call	mscale
	movl	%eax, %ebx
	movsd	.L307, %xmm7 # 1
	movsd	48(%esp), %xmm1
	movapd	%xmm7, %xmm0
	divsd	%xmm1, %xmm0
	movsd	64(%esp), %xmm3
	movapd	%xmm7, %xmm1
	divsd	%xmm3, %xmm1
	movsd	56(%esp), %xmm2
	divsd	%xmm2, %xmm7
	movsd	%xmm0, 0(%esp)
	movsd	%xmm1, 8(%esp)
	movsd	%xmm7, 16(%esp)
	call	mscale
	movl	%esi, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%eax, 8(%esp)
	movsd	40(%esp), %xmm2
	movsd	%xmm2, 12(%esp)
	call	transform
	movl	28(%esp), %ebx
	movl	32(%esp), %esi
	addl	$76, %esp
	ret
	.cfi_endproc
	.type	oscale, @function
	.size	oscale, . - oscale
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L307:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl otranslate
otranslate:
	.cfi_startproc
	subl	$68, %esp
	.cfi_adjust_cfa_offset	68
	leal	72(%esp), %edx
	movl	%edx, 24(%esp)
	movl	%ebx, 28(%esp)
	movl	%esi, 32(%esp)
	movl	0(%edx), %esi
	movsd	4(%edx), %xmm4
	movsd	%xmm4, 56(%esp)
	movsd	12(%edx), %xmm4
	movsd	%xmm4, 40(%esp)
	movsd	20(%edx), %xmm4
	movsd	%xmm4, 48(%esp)
	movsd	56(%esp), %xmm6
	movsd	%xmm6, 0(%esp)
	movsd	40(%esp), %xmm6
	movsd	%xmm6, 8(%esp)
	movsd	48(%esp), %xmm6
	movsd	%xmm6, 16(%esp)
	call	mtranslate
	movl	%eax, %ebx
	movsd	56(%esp), %xmm2
	xorpd	__negd_mask, %xmm2
	movsd	40(%esp), %xmm0
	xorpd	__negd_mask, %xmm0
	movsd	48(%esp), %xmm1
	xorpd	__negd_mask, %xmm1
	movsd	%xmm2, 0(%esp)
	movsd	%xmm0, 8(%esp)
	movsd	%xmm1, 16(%esp)
	call	mtranslate
	movsd	.L308, %xmm5 # 1
	movl	%esi, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%eax, 8(%esp)
	movsd	%xmm5, 12(%esp)
	call	transform
	movl	28(%esp), %ebx
	movl	32(%esp), %esi
	addl	$68, %esp
	ret
	.cfi_endproc
	.type	otranslate, @function
	.size	otranslate, . - otranslate
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L308:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl ouscale
ouscale:
	.cfi_startproc
	subl	$60, %esp
	.cfi_adjust_cfa_offset	60
	leal	64(%esp), %edx
	movl	%edx, 24(%esp)
	movl	%ebx, 28(%esp)
	movl	%esi, 32(%esp)
	movl	0(%edx), %esi
	movsd	4(%edx), %xmm2
	movsd	%xmm2, 40(%esp)
	movsd	.L309, %xmm1 # 1
	movsd	40(%esp), %xmm0
	divsd	%xmm0, %xmm1
	movsd	%xmm1, 48(%esp)
	movsd	40(%esp), %xmm4
	movsd	%xmm4, 0(%esp)
	movsd	40(%esp), %xmm4
	movsd	%xmm4, 8(%esp)
	movsd	40(%esp), %xmm4
	movsd	%xmm4, 16(%esp)
	call	mscale
	movl	%eax, %ebx
	movsd	48(%esp), %xmm5
	movsd	%xmm5, 0(%esp)
	movsd	48(%esp), %xmm5
	movsd	%xmm5, 8(%esp)
	movsd	48(%esp), %xmm5
	movsd	%xmm5, 16(%esp)
	call	mscale
	movl	%esi, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%eax, 8(%esp)
	movsd	40(%esp), %xmm3
	movsd	%xmm3, 12(%esp)
	call	transform
	movl	28(%esp), %ebx
	movl	32(%esp), %esi
	addl	$60, %esp
	ret
	.cfi_endproc
	.type	ouscale, @function
	.size	ouscale, . - ouscale
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L309:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl odifference
odifference:
	.cfi_startproc
	subl	$20, %esp
	.cfi_adjust_cfa_offset	20
	leal	24(%esp), %edx
	movl	%edx, 4(%esp)
	movl	%ebx, 8(%esp)
	movl	%esi, 12(%esp)
	movl	0(%edx), %esi
	movl	4(%edx), %ebx
	movl	$68, %eax
	movl	%eax, 0(%esp)
	call	arena_alloc
	movl	$7, %edx
	movl	%edx, 0(%eax)
	movl	%esi, 28(%eax)
	movl	%ebx, 32(%eax)
	movsd	.L310, %xmm0 # -1
	movsd	%xmm0, 60(%eax)
	movl	8(%esp), %ebx
	movl	12(%esp), %esi
	addl	$20, %esp
	ret
	.cfi_endproc
	.type	odifference, @function
	.size	odifference, . - odifference
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L310:	.quad	0xbff0000000000000
	.text
	.align	16
	.globl ointersect
ointersect:
	.cfi_startproc
	subl	$20, %esp
	.cfi_adjust_cfa_offset	20
	leal	24(%esp), %edx
	movl	%edx, 4(%esp)
	movl	%ebx, 8(%esp)
	movl	%esi, 12(%esp)
	movl	0(%edx), %esi
	movl	4(%edx), %ebx
	movl	$68, %eax
	movl	%eax, 0(%esp)
	call	arena_alloc
	movl	$6, %edx
	movl	%edx, 0(%eax)
	movl	%esi, 28(%eax)
	movl	%ebx, 32(%eax)
	movsd	.L311, %xmm0 # -1
	movsd	%xmm0, 60(%eax)
	movl	8(%esp), %ebx
	movl	12(%esp), %esi
	addl	$20, %esp
	ret
	.cfi_endproc
	.type	ointersect, @function
	.size	ointersect, . - ointersect
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L311:	.quad	0xbff0000000000000
	.text
	.align	16
	.globl ounion
ounion:
	.cfi_startproc
	subl	$20, %esp
	.cfi_adjust_cfa_offset	20
	leal	24(%esp), %edx
	movl	%edx, 4(%esp)
	movl	%ebx, 8(%esp)
	movl	%esi, 12(%esp)
	movl	0(%edx), %esi
	movl	4(%edx), %ebx
	movl	$68, %eax
	movl	%eax, 0(%esp)
	call	arena_alloc
	movl	$5, %edx
	movl	%edx, 0(%eax)
	movl	%esi, 28(%eax)
	movl	%ebx, 32(%eax)
	movsd	.L312, %xmm0 # -1
	movsd	%xmm0, 60(%eax)
	movl	8(%esp), %ebx
	movl	12(%esp), %esi
	addl	$20, %esp
	ret
	.cfi_endproc
	.type	ounion, @function
	.size	ounion, . - ounion
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L312:	.quad	0xbff0000000000000
	.text
	.align	16
normal_vector_object:
	.cfi_startproc
	subl	$36, %esp
	.cfi_adjust_cfa_offset	36
	leal	40(%esp), %edx
	movl	%edx, 16(%esp)
	movl	%ebx, 20(%esp)
	movl	%esi, 24(%esp)
	movl	0(%edx), %ecx
	movl	4(%edx), %esi
	movl	8(%edx), %eax
	movl	12(%edx), %ebx
	movl	0(%ecx), %edx
	cmpl	$2, %edx
	jae	.L313
	testl	%edx, %edx
	jne	.L314
	testl	%eax, %eax
	jne	.L315
	movsd	0(%esi), %xmm6
	movsd	%xmm6, 0(%ebx)
	movsd	8(%esi), %xmm0
	xorpd	__negd_mask, %xmm0
	movsd	%xmm0, 8(%ebx)
	movsd	16(%esi), %xmm7
	movsd	%xmm7, 16(%ebx)
	jmp	.L316
.L315:
	xorpd	%xmm3, %xmm3
	movsd	%xmm3, 0(%ebx)
	movsd	.L317, %xmm4 # 1
	movsd	%xmm4, 8(%ebx)
	movsd	%xmm3, 16(%ebx)
	jmp	.L316
.L314:
	cmpl	$3, %eax
	jae	.L318
	testl	%eax, %eax
	je	.L319
	cmpl	$1, %eax
	jne	.L320
	xorpd	%xmm1, %xmm1
	movsd	%xmm1, 0(%ebx)
	movsd	%xmm1, 8(%ebx)
	movsd	.L321, %xmm0 # 1
	movsd	%xmm0, 16(%ebx)
	jmp	.L316
.L320:
	movsd	.L322, %xmm0 # -1
	movsd	%xmm0, 0(%ebx)
	xorpd	%xmm2, %xmm2
	movsd	%xmm2, 8(%ebx)
	movsd	%xmm2, 16(%ebx)
	jmp	.L316
.L319:
	xorpd	%xmm4, %xmm4
	movsd	%xmm4, 0(%ebx)
	movsd	%xmm4, 8(%ebx)
	movsd	.L323, %xmm2 # -1
	movsd	%xmm2, 16(%ebx)
	jmp	.L316
.L318:
	cmpl	$3, %eax
	je	.L324
	cmpl	$4, %eax
	je	.L325
	cmpl	$5, %eax
	jne	.L316
	xorpd	%xmm7, %xmm7
	movsd	%xmm7, 0(%ebx)
	movsd	.L326, %xmm3 # -1
	movsd	%xmm3, 8(%ebx)
	movsd	%xmm7, 16(%ebx)
	jmp	.L316
.L325:
	xorpd	%xmm1, %xmm1
	movsd	%xmm1, 0(%ebx)
	movsd	.L327, %xmm6 # 1
	movsd	%xmm6, 8(%ebx)
	movsd	%xmm1, 16(%ebx)
	jmp	.L316
.L324:
	movsd	.L328, %xmm4 # 1
	movsd	%xmm4, 0(%ebx)
	xorpd	%xmm0, %xmm0
	movsd	%xmm0, 8(%ebx)
	movsd	%xmm0, 16(%ebx)
	jmp	.L316
.L313:
	cmpl	$2, %edx
	je	.L329
	cmpl	$3, %edx
	je	.L330
	cmpl	$4, %edx
	jne	.L331
	movsd	0(%esi), %xmm1
	movsd	%xmm1, 0(%ebx)
	movsd	8(%esi), %xmm6
	movsd	%xmm6, 8(%ebx)
	movsd	16(%esi), %xmm3
	movsd	%xmm3, 16(%ebx)
	jmp	.L316
.L331:
	leal	__stringlit_2, %ecx
	leal	__stringlit_1, %esi
	movl	$170, %ebx
	xorl	%edx, %edx
	movl	%ecx, 0(%esp)
	movl	%esi, 4(%esp)
	movl	%ebx, 8(%esp)
	movl	%edx, 12(%esp)
	call	__assert_fail
	jmp	.L316
.L330:
	xorpd	%xmm6, %xmm6
	movsd	%xmm6, 0(%ebx)
	movsd	.L332, %xmm5 # 1
	movsd	%xmm5, 8(%ebx)
	movsd	%xmm6, 16(%ebx)
	jmp	.L316
.L329:
	testl	%eax, %eax
	je	.L333
	cmpl	$1, %eax
	je	.L334
	cmpl	$2, %eax
	jne	.L316
	xorpd	%xmm2, %xmm2
	movsd	%xmm2, 0(%ebx)
	movsd	.L335, %xmm4 # -1
	movsd	%xmm4, 8(%ebx)
	movsd	%xmm2, 16(%ebx)
	jmp	.L316
.L334:
	xorpd	%xmm5, %xmm5
	movsd	%xmm5, 0(%ebx)
	movsd	.L336, %xmm1 # 1
	movsd	%xmm1, 8(%ebx)
	movsd	%xmm5, 16(%ebx)
	jmp	.L316
.L333:
	movsd	0(%esi), %xmm7
	movsd	%xmm7, 0(%ebx)
	xorpd	%xmm5, %xmm5
	movsd	%xmm5, 8(%ebx)
	movsd	16(%esi), %xmm5
	movsd	%xmm5, 16(%ebx)
.L316:
	movl	20(%esp), %ebx
	movl	24(%esp), %esi
	addl	$36, %esp
	ret
	.cfi_endproc
	.type	normal_vector_object, @function
	.size	normal_vector_object, . - normal_vector_object
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L336:	.quad	0x3ff0000000000000
.L335:	.quad	0xbff0000000000000
.L332:	.quad	0x3ff0000000000000
.L328:	.quad	0x3ff0000000000000
.L327:	.quad	0x3ff0000000000000
.L326:	.quad	0xbff0000000000000
.L323:	.quad	0xbff0000000000000
.L322:	.quad	0xbff0000000000000
.L321:	.quad	0x3ff0000000000000
.L317:	.quad	0x3ff0000000000000
	.text
	.align	16
tangent_vectors:
	.cfi_startproc
	subl	$20, %esp
	.cfi_adjust_cfa_offset	20
	leal	24(%esp), %edx
	movl	%edx, 0(%esp)
	movl	%ebx, 4(%esp)
	movl	%esi, 8(%esp)
	movl	0(%edx), %ebx
	movl	4(%edx), %eax
	movl	8(%edx), %esi
	movsd	8(%ebx), %xmm4
	xorpd	%xmm0, %xmm0
	comisd	%xmm0, %xmm4
	ja	.L337
	comisd	%xmm0, %xmm4
	jp	.L339
	je	.L338
.L339:
	movsd	%xmm4, 0(%eax)
	movsd	0(%ebx), %xmm1
	xorpd	__negd_mask, %xmm1
	movsd	%xmm1, 8(%eax)
	movsd	%xmm0, 16(%eax)
	movsd	%xmm0, 0(%esi)
	movsd	16(%ebx), %xmm5
	xorpd	__negd_mask, %xmm5
	movsd	%xmm5, 8(%esi)
	movsd	8(%ebx), %xmm0
	movsd	%xmm0, 16(%esi)
	jmp	.L340
.L338:
	movsd	16(%ebx), %xmm4
	movsd	%xmm4, 0(%eax)
	movsd	%xmm0, 8(%eax)
	movsd	0(%ebx), %xmm2
	xorpd	__negd_mask, %xmm2
	movsd	%xmm2, 16(%eax)
	movsd	16(%ebx), %xmm1
	movsd	%xmm1, 0(%esi)
	movsd	.L341, %xmm5 # 1
	movsd	%xmm5, 8(%esi)
	movsd	0(%ebx), %xmm6
	xorpd	__negd_mask, %xmm6
	movsd	%xmm6, 16(%esi)
	jmp	.L340
.L337:
	movsd	%xmm4, 0(%eax)
	movsd	0(%ebx), %xmm3
	xorpd	__negd_mask, %xmm3
	movsd	%xmm3, 8(%eax)
	movsd	%xmm0, 16(%eax)
	movsd	%xmm0, 0(%esi)
	movsd	16(%ebx), %xmm2
	movsd	%xmm2, 8(%esi)
	movsd	8(%ebx), %xmm7
	xorpd	__negd_mask, %xmm7
	movsd	%xmm7, 16(%esi)
.L340:
	movl	4(%esp), %ebx
	movl	8(%esp), %esi
	addl	$20, %esp
	ret
	.cfi_endproc
	.type	tangent_vectors, @function
	.size	tangent_vectors, . - tangent_vectors
	.section	.rodata.cst8,"aM",@progbits,8
	.align	8
.L341:	.quad	0x3ff0000000000000
	.text
	.align	16
	.globl normal_vector
normal_vector:
	.cfi_startproc
	subl	$180, %esp
	.cfi_adjust_cfa_offset	180
	leal	184(%esp), %edx
	movl	%edx, 16(%esp)
	movl	%ebx, 20(%esp)
	movl	%esi, 24(%esp)
	movl	%edi, 28(%esp)
	movl	0(%edx), %esi
	movl	4(%edx), %eax
	movl	8(%edx), %edi
	movl	12(%edx), %ebx
	movl	12(%esi), %edx
	leal	80(%esp), %ecx
	movl	%edx, 0(%esp)
	movl	%eax, 4(%esp)
	movl	%ecx, 8(%esp)
	call	apply_to_point
	leal	80(%esp), %ecx
	leal	104(%esp), %edx
	movl	%esi, 0(%esp)
	movl	%ecx, 4(%esp)
	movl	%edi, 8(%esp)
	movl	%edx, 12(%esp)
	call	normal_vector_object
	leal	104(%esp), %edx
	leal	128(%esp), %ecx
	leal	152(%esp), %edi
	movl	%edx, 0(%esp)
	movl	%ecx, 4(%esp)
	movl	%edi, 8(%esp)
	call	tangent_vectors
	movl	16(%esi), %edi
	leal	128(%esp), %edx
	leal	32(%esp), %eax
	movl	%edi, 0(%esp)
	movl	%edx, 4(%esp)
	movl	%eax, 8(%esp)
	call	apply_to_vect
	movl	16(%esi), %edx
	leal	152(%esp), %eax
	leal	56(%esp), %esi
	movl	%edx, 0(%esp)
	movl	%eax, 4(%esp)
	movl	%esi, 8(%esp)
	call	apply_to_vect
	leal	32(%esp), %ecx
	leal	56(%esp), %eax
	movl	%ecx, 0(%esp)
	movl	%eax, 4(%esp)
	movl	%ebx, 8(%esp)
	call	product
	movl	%ebx, 0(%esp)
	movl	%ebx, 4(%esp)
	call	vnormalize
	movl	20(%esp), %ebx
	movl	24(%esp), %esi
	movl	28(%esp), %edi
	addl	$180, %esp
	ret
	.cfi_endproc
	.type	normal_vector, @function
	.size	normal_vector, . - normal_vector
	.section	.rodata
	.align	16
__negd_mask:	.quad   0x8000000000000000, 0
__absd_mask:	.quad   0x7FFFFFFFFFFFFFFF, 0xFFFFFFFFFFFFFFFF
__negs_mask:	.long   0x80000000, 0, 0, 0
__abss_mask:	.long   0x7FFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF
